{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 11  \n",
    "Implement Hidden Markov Model with supervised training and Viterbi algorithm for finding the most probable sequence of hidden states. Use [Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) for estimation of probabilities. Apply the developed model to the problems:\n",
    "* part of speech tagging\n",
    "* spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from IPython.display import Image\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM model for 3-grams:\n",
    "\n",
    "$P(x_1, .., x_T, y_1, .., y_T, y_{T+1}) = \\prod_{t=1}^{T+1} q(y_t | y_{t-2}, y_{t-1}) \\prod_{t=1}^T e(x_t | y_t)$\n",
    "\n",
    "$x_1, .., x_T$ - sequence of observed states of length T  \n",
    "$y_1, .., y_T$ - sequence of hidden states of length T  \n",
    "$q(i | u, v) = \\frac {count(u, v, i)} {count(u, v)} $ - transition probability   \n",
    "$e(x_k | i) = \\frac {count(i, x_k)} {count(i)}$ - emission probability  \n",
    "$A_{i,j} = A_{(u,v), j} = q(i | u, v)$ - transition matrix  \n",
    "$B_{j,k} = e(x_k | j)$ - emission matrix  \n",
    "\n",
    "We assume, that $y_{T+1} = TERM$, and $y_0 = y_{-1} = START$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    START = '*'\n",
    "    TERM = '$'\n",
    "    REST = '$REST$' # to deal with observed states who have never appeared in train dataset.\n",
    "        \n",
    "    def cond_idx(self, u, v):\n",
    "        return u + v*self.h_dim\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X - list of lists, observed states\n",
    "        y - list of lists, hidden states\n",
    "        estimate elements of A, B matrices from train sequence. \n",
    "        \"\"\"\n",
    "        \n",
    "        #######################\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        self.hidden_idx2state = ([list(var) for var in set(tuple(var) for var in y)])\n",
    "        self.hidden_idx2state.append([self.START, self.TERM])\n",
    "            # lisf of unique hidden states in train sequence + [START, TERM]\n",
    "        self.hidden_states = y\n",
    "            # from state name to state index in hidden_idx2state\n",
    "        self.h_dim = len(y)\n",
    "        \n",
    "        self.observed_idx2state = [list(var) for var in set(tuple(var) for var in X)].append([self.START, self.TERM])\n",
    "        self.observed_states = X\n",
    "        self.o_dim = len(X)\n",
    "        \n",
    "        #######################       \n",
    "        \n",
    "        \n",
    "        #######################\n",
    "        # estimate emission matrix\n",
    "        # YOUR CODE HERE\n",
    "        self.B =sparse.csr_matrix( (self.h_dim,self.o_dim) )\n",
    "        \n",
    "        #######################\n",
    "        \n",
    "        self.B_rowsum = np.ravel(self.B.sum(axis=1))\n",
    "        \n",
    "        \n",
    "        ########################\n",
    "        # transition matrix\n",
    "        # YOUR CODE HERE\n",
    "        self.A = sparse.csr_matrix( (self.h_dim **2,self.h_dim))\n",
    "      #  sparse.csr_matrix.todense(self.A)\n",
    "        #dense matrix of shape (h_dim **2, h_dim)\n",
    "        \n",
    "        #remember about padding for sequence of hidden states, eg {a, b} -> {START, START, a, b, TERM}\n",
    "        ########################\n",
    "        \n",
    "        self.A_rowsum = np.ravel(self.A.sum(axis=1))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def tr_prob(self, i, j):\n",
    "        \"\"\"\n",
    "        A_ij = q(j | i) = q(j| u, v) with Laplace smoothing\n",
    "        \"\"\"\n",
    "        ########################\n",
    "        # YOUR CODE HERE\n",
    "        result = (j*i+1)/(i + self.v)\n",
    "        ########################\n",
    "        return result\n",
    "    \n",
    "    def em_prob(self, i, j):\n",
    "        \"\"\"\n",
    "        B_jk = e(x_k| j) with Laplace smoothing\n",
    "        \"\"\"\n",
    "        ########################\n",
    "        # YOUR CODE HERE\n",
    "        result = (x_k*j + 1)/(j + self.v)\n",
    "        ########################\n",
    "        return result\n",
    "        \n",
    "    def o_state(self, x):\n",
    "        \"\"\"\n",
    "        return index of obseved state\n",
    "        \"\"\"\n",
    "        return self.observed_states.get(x, self.observed_states[self.REST])\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the most probable sequence of hidden states for every sequence of observed states\n",
    "        X - list of lists\n",
    "        \"\"\"\n",
    "        y_pred = [self._viterbi(seq) for seq in X]\n",
    "        return y_pred \n",
    "            \n",
    "    def _viterbi(self, X):\n",
    "        \"\"\"\n",
    "        X - list of observables\n",
    "        product of probabilities usually is not numerically stable\n",
    "        remember, that log(ab) = log(a) + log(b) and argmax[log(f(x))] = argmax[f(x)]\n",
    "        \n",
    "        \"\"\"   \n",
    "        T = len(X)\n",
    "        \n",
    "        # pi[t, u, v] - max probability for any state sequence ending with x_t = v and x_{t-1} = u.\n",
    "        pi = np.zeros((T + 1, self.h_dim, self.h_dim))\n",
    "        # backpointers, bp[t, u, v] = argmax probability for any state sequence ending with x_t = v and x_{t-1} = u.\n",
    "        bp = np.zeros((T + 1, self.h_dim, self.h_dim), dtype=np.int)\n",
    "        \n",
    "        ###################\n",
    "        # fill tables pi and bp\n",
    "        # pi[t, u, v] = max_{w} [ pi[t-1, w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # bp[t, u, v] = argmax_{w} [ pi[t-1, w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # YOUR CODE HERE \n",
    "        for k in range(1, T + 1):\n",
    "             xk = self.o_state(X[k-1])\n",
    "            \n",
    "             for v in range(self.h_dim):\n",
    "                 log_b_smoothed = np.log(b) \n",
    "                 for u in range(self.h_dim): \n",
    "                     r = np.zeros(self.h_dim)\n",
    "                     for w in range(self.h_dim):\n",
    "                         log_a_smoothed = np.log(a)\n",
    "                         r[w] = log_b_smoothed/log_a_smoothed\n",
    "                     bp[k, u, v] = np.argmax(r)\n",
    "                     pi[k, u, v] = np.max(r)\n",
    "        ###################\n",
    "                    \n",
    "        term_idx = self.hidden_states[self.TERM]\n",
    "        \n",
    "        ###################\n",
    "        # r(u,v) = pi[T, u, v] * q(TERM | u, v)\n",
    "        # find argmax_{u, v} r(u, v)\n",
    "        # YOUR CODE HERE\n",
    "        u, v = pi[u, v]\n",
    "        ###################\n",
    "\n",
    "        h_states = [v, u]\n",
    "        ###################\n",
    "        # rollback backpointers\n",
    "        # y_{t-2} = bp[t, y_{t-1}, y_t]\n",
    "        # h_states is a reversed sequence of hidden states\n",
    "        # YOUR CODE HERE\n",
    "        h_states = y.reverse()\n",
    "            \n",
    "        ###################        \n",
    "            \n",
    "        return [self.hidden_idx2state[i] for i in reversed(h_states[:T])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. Part of speech tagging\n",
    "\n",
    "Build Part-of-Speech tagging model using HMM. Estimate accuracy on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /home/yura/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import treebank\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
      "tags:  NNP NNP , CD NNS JJ , MD VB DT NN IN DT JJ NN NNP CD .\n"
     ]
    }
   ],
   "source": [
    "data = treebank.tagged_sents()[:3000]\n",
    "test_data = treebank.tagged_sents()[3000:3010]\n",
    "\n",
    "X_train = [[x[0] for x in y] for y in data]\n",
    "y_train = [[x[1] for x in y] for y in data]\n",
    "\n",
    "X_test = [[x[0] for x in y] for y in test_data]\n",
    "y_test = [[x[1] for x in y] for y in test_data]\n",
    "\n",
    "print('sentence: ', \" \".join(X_train[0]))\n",
    "print('tags: ', \" \".join(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):       \n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    \n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f0dc62f862ad>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \"\"\"\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_viterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f0dc62f862ad>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \"\"\"\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_viterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f0dc62f862ad>\u001b[0m in \u001b[0;36m_viterbi\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# pi[t, u, v] - max probability for any state sequence ending with x_t = v and x_{t-1} = u.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;31m# backpointers, bp[t, u, v] = argmax probability for any state sequence ending with x_t = v and x_{t-1} = u.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hh = HMM().fit(X_train, y_train)\n",
    "y_pred = hh.predict(X_test)\n",
    "print(accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your accuracy must be > 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.2 Vectorized viterbi\n",
    "Our currrent implementation of Viterbi is too slow. Let's make it vectorized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HmmVectorized(HMM):\n",
    "    \n",
    "    def _viterbi(self, X):\n",
    "        \"\"\"\n",
    "        Vectorized version of Viterbi. Let's speed up!\n",
    "        X - list of observables\n",
    "        \"\"\"   \n",
    "        T = len(X)\n",
    "        \n",
    "        # One may notice, at every step t we only need pi[t-1, u, v] = pi_prev[u,v] to compute pi[t, u, v] = pi_curr[u,v]\n",
    "        pi_prev = np.zeros((self.h_dim, self.h_dim))\n",
    "        \n",
    "        # backpointers\n",
    "        bp = np.zeros((T + 1, self.h_dim, self.h_dim), dtype=np.int)\n",
    "        \n",
    "        a_rowsum = self.A_rowsum.reshape(self.h_dim, self.h_dim)\n",
    "        \n",
    "        ###################\n",
    "        # fill pi and bp\n",
    "        # pi_curr[u, v] = max_{w} [ pi_prev[w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # bp[t, u, v] = argmax_{w} [ pi_prev[w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # don't use tr_prob() and em_prob(), apply laplace smoothing directly here\n",
    "        # YOUR CODE HERE\n",
    "#         for k in range(1, T + 1):            \n",
    "#             xk = self.o_state(X[k-1])\n",
    "#             pi_curr = np.zeros_like(pi_prev)\n",
    "            \n",
    "#             for v in range(self.h_dim):\n",
    "#                 log_b_smoothed = \n",
    "#                 a = self.A[:, v].reshape(self.h_dim, self.h_dim)\n",
    "#                 log_a_smoothed = \n",
    "#                 r =  \n",
    "#                 bp[k, :, v] = np.argmax(r, axis=1)\n",
    "#                 pi_curr[:, v] = np.max(r, axis=1)\n",
    "                    \n",
    "#             pi_prev = pi_curr\n",
    "        ###################\n",
    "        \n",
    "        term_idx = self.hidden_states[self.TERM]\n",
    "        \n",
    "        ###################\n",
    "        # r(u,v) = pi[T, u, v] * q(TERM | u, v)\n",
    "        # find argmax_{u, v} r(u, v)\n",
    "        # express r(u,v) as matrix additions\n",
    "        # YOUR CODE HERE\n",
    "        # u, v = \n",
    "        ###################\n",
    "        \n",
    "        h_states = [v, u]\n",
    "        ###################\n",
    "        # rollback backpointers\n",
    "        # y_{t-2} = bp[t, y_{t-1}, y_t]\n",
    "        # h_states is a reversed sequence of hidden states\n",
    "        # YOUR CODE HERE\n",
    "        # h_states = \n",
    "            \n",
    "        ###################\n",
    "        \n",
    "        return [self.hidden_idx2state[i] for i in reversed(h_states[:T])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a larger test subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
      "tags:  NNP NNP , CD NNS JJ , MD VB DT NN IN DT JJ NN NNP CD .\n"
     ]
    }
   ],
   "source": [
    "data = treebank.tagged_sents()[:3000]\n",
    "test_data = treebank.tagged_sents()[3000:3300]\n",
    "\n",
    "X_train = [[x[0] for x in y] for y in data]\n",
    "y_train = [[x[1] for x in y] for y in data]\n",
    "\n",
    "X_test = [[x[0] for x in y] for y in test_data]\n",
    "y_test = [[x[1] for x in y] for y in test_data]\n",
    "\n",
    "print('sentence: ', \" \".join(X_train[0]))\n",
    "print('tags: ', \" \".join(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-538d8c6dd2ac>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_dim\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;31m#dense matrix of shape (h_dim **2, h_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mtodense\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mshares\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \"\"\"\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;31m##############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hh = HmmVectorized().fit(X_train, y_train)\n",
    "y_pred = hh.predict(X_test)\n",
    "print(accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your accuracy must be > 0.84 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. Spelling correction\n",
    "\n",
    "Given data of true_char corrupted\\_char build spelling correction model using HMM.    \n",
    "There are 2 datatsets (spelling10.txt, spelling20.txt) with 10% and 20% corruption probability respectively.  \n",
    "Each dataset contains 30556 words. Use first 28000 for training and the rest for testing. Estimate accuracy on the test subset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get > 93% accuracy (+3%) on spelling10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get > 89% accuracy (+9%) on spelling20 dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
